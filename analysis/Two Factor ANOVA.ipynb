{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Two Factor ANOVA with replication\n",
    "\n",
    "Using data from:\n",
    "\n",
    "http://www.real-statistics.com/two-way-anova/two-factor-anova-with-replication/\n",
    "\n",
    "Note that this implements a two factor univariate ANOVA with replication of data points. BOTH factors are fixed factors in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheat_values [ 123.  156.  112.  100.  168.  135.  130.  176.  120.  155.  156.  180.\n",
      "  147.  146.  193.]\n",
      "wheat_mean 146.466666667\n",
      "GRAND MEAN: 157.45\n",
      "TOTAL variance: 671.878813559 sigma: 25.920625254 sos: 39640.85 dof: 59\n",
      "ERROR/WG variance: 442.091666667 sigma: 21.025975998 sos: 21220.4 dof: 48\n",
      "Add  131.8 to wheat_treatment_mean\n",
      "Add  143.2 to wheat_treatment_mean\n",
      "Add  164.4 to wheat_treatment_mean\n",
      "CONDITION variance: 1137.21666667 sigma: 33.7226432337 sos: 3411.65 dof: 3\n",
      "INDIVIDUAL variance: 4391.45 sigma: 66.2680164182 sos: 8782.9 dof: 2\n",
      "wg_dof: 48 wg_dof_alt: 48\n",
      "INTERACTION variance (by subtraction): 1037.65 sigma: 32.2125751842 sos: 6225.9 dof: 6\n",
      "INTERACTION variance2 (by computation)): 1037.65 sigma: 32.2125751842 sos: 6225.9 dof: 6\n",
      "\n",
      "F_cond:2.57235490377 P_cond:0.0649438221616 \n",
      "F_ind:9.93334715651 P_ind:0.000245487281371\n",
      "F_interaction:2.34713765999 P_interaction:0.0455554921365\n",
      "\n",
      "\n",
      "Source of var, Sumof Squares, df, Mean square , F ratio         P\n",
      "-------------------------------------------------------------------\n",
      "Individual   , 8782.9, 2, 4391.45, 9.93334715651, 0.000245487281371\n",
      "Condition    , 3411.65, 3, 1137.21666667, 2.57235490377, 0.0649438221616\n",
      "Indiv x Cond , 6225.9, 6, 1037.65, 2.34713765999, 0.0455554921365\n",
      "Error        , 21220.4, 48, 442.091666667, -, -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import special\n",
    "\n",
    "# I'll call this class individual, so it matches the code for my real experiment. However,\n",
    "# this is really the factor called \"blends\" in the sample.\n",
    "class individual:\n",
    "    def __init__(self, blend_id):\n",
    "        self.blend_id = blend_id;\n",
    "        self.wheat_values = np.ndarray(1)\n",
    "        self.corn_values = np.ndarray(1)\n",
    "        self.soy_values = np.ndarray(1)\n",
    "        self.rice_values = np.ndarray(1)\n",
    "\n",
    "    def overall_mean(self):\n",
    "        all_ = np.concatenate((self.wheat_values, self.corn_values, self.soy_values, self.rice_values))\n",
    "        return all_.mean()\n",
    "\n",
    "    def overall_std(self):\n",
    "        all_ = np.concatenate((self.no_dist_latencies, self.sync_latencies, self.async_latencies))\n",
    "        return all_.std()\n",
    "\n",
    "    def excludeOutlier (self, num_sds, values):\n",
    "        r = 0\n",
    "        while r < values.size:\n",
    "            upperlimit = values.mean() + values.std()*num_sds\n",
    "            lowerlimit = values.mean() - values.std()*num_sds\n",
    "            if values[r] > upperlimit or values[r] < lowerlimit:\n",
    "                # outlier, so delete\n",
    "                values = np.delete (values, r, 0)\n",
    "                r = r - 1\n",
    "            r = r + 1\n",
    "        return values\n",
    "\n",
    "    def excludeOutliers (self, num_sds):\n",
    "        #print \"Removing outliers\", num_sds, \"SDs away from the mean\"\n",
    "        self.wheat_values = self.excludeOutlier(num_sds, self.wheat_values)\n",
    "        self.corn_values = self.excludeOutlier(num_sds, self.corn_values)\n",
    "        self.soy_values = self.excludeOutlier(num_sds, self.soy_values)\n",
    "        self.rice_values = self.excludeOutlier(num_sds, self.rice_values)\n",
    "        # Compute the sum of the squared displacements from the mean for all three conditions\n",
    "\n",
    "    def sumofsquare_displacements_all_from_value(self, value):\n",
    "        sos = self.sumofsquare_displacements_from_value(0,value) + self.sumofsquare_displacements_from_value(1,value) + self.sumofsquare_displacements_from_value(2,value) + self.sumofsquare_displacements_from_value(3,value)\n",
    "        return sos\n",
    "\n",
    "    # Compute the sum of the squared displacements from the mean for all three conditions\n",
    "    def sumofsquare_displacements_all(self):\n",
    "        sos = self.sumofsquare_displacements(0) + self.sumofsquare_displacements(1) + self.sumofsquare_displacements(2) + self.sumofsquare_displacements(3)\n",
    "        return sos\n",
    "\n",
    "    # Compute the sum of the squared displacements from the mean for the given condition\n",
    "    def sumofsquare_displacements(self, condition):\n",
    "        if condition == 0:\n",
    "            mn = self.wheat_values.mean()\n",
    "            squares = np.power((self.wheat_values - mn), 2)\n",
    "        elif condition == 1:\n",
    "            mn = self.corn_values.mean()\n",
    "            squares = np.power((self.corn_values - mn), 2)\n",
    "        elif condition == 2:\n",
    "            mn = self.soy_values.mean()\n",
    "            squares = np.power((self.soy_values - mn), 2)\n",
    "        else: # condition 3\n",
    "            mn = self.rice_values.mean()\n",
    "            squares = np.power((self.rice_values - mn), 2)\n",
    "        sos = np.sum(squares)\n",
    "        return sos\n",
    "    \n",
    "    # Compute the sum of the squared displacements from the mean for the given condition\n",
    "    def sumofsquare_displacements_from_value(self, condition, value):\n",
    "        if condition == 0:\n",
    "            squares = np.power((self.wheat_values - value), 2)\n",
    "        elif condition == 1:\n",
    "            squares = np.power((self.corn_values - value), 2)\n",
    "        elif condition == 2:\n",
    "            squares = np.power((self.soy_values - value), 2)\n",
    "        else: # condition 3\n",
    "            squares = np.power((self.rice_values - value), 2)\n",
    "        sos = np.sum(squares)\n",
    "        return sos\n",
    "\n",
    "    def num_replicates_all(self):\n",
    "        n = self.num_replicates(0) + self.num_replicates(1) + self.num_replicates(2) + self.num_replicates(3)\n",
    "        return n\n",
    "\n",
    "    def num_replicates(self, condition):\n",
    "        if condition == 0:\n",
    "            return self.wheat_values.size\n",
    "        elif condition == 1:\n",
    "            return self.corn_values.size\n",
    "        elif condition == 2:\n",
    "            return self.soy_values.size\n",
    "        else: # condition 3\n",
    "            return self.rice_values.size\n",
    "\n",
    "def twofactor_anova(individuals):\n",
    "\n",
    "    # This is a two factor anova WITH replication, as we have replicated measurements\n",
    "    # (of the latency) for each individual/condition combination.\n",
    "    #\n",
    "    # This code follows the example in McKillup section 13.3 (p174), in which there are multiple\n",
    "    # measurements for each FactorA/B combination (just as we have multiple latency readings for\n",
    "    # each individual in each experimental condition)\n",
    "\n",
    "    # Containers to fill\n",
    "    wheat_values = [];\n",
    "    corn_values = [];\n",
    "    soy_values = [];\n",
    "    rice_values = [];\n",
    "    \n",
    "    # Zeroth, exclude outliers:\n",
    "    # In this same loop, extract the latencies into external containers:\n",
    "    for ind in individuals:\n",
    "        #ind = individuals[i]\n",
    "        ind.excludeOutliers(2)\n",
    "        wheat_values = np.concatenate((wheat_values, ind.wheat_values))\n",
    "        corn_values = np.concatenate((corn_values, ind.corn_values))\n",
    "        soy_values = np.concatenate((soy_values, ind.soy_values))\n",
    "        rice_values = np.concatenate((rice_values, ind.rice_values))\n",
    "    \n",
    "    print 'wheat_values',wheat_values\n",
    "    \n",
    "    # Compute condition means\n",
    "    wheat_mean = wheat_values.mean()\n",
    "    corn_mean = corn_values.mean()\n",
    "    soy_mean = soy_values.mean()\n",
    "    rice_mean = rice_values.mean()\n",
    "\n",
    "    # Compute grand mean\n",
    "    all_latencies = np.concatenate((wheat_values,corn_values,soy_values,rice_values))\n",
    "    grand_mean = all_latencies.mean()\n",
    "    print 'GRAND MEAN:',grand_mean\n",
    "\n",
    "    # First compute within-group variance. This means computing the sum of squares for each individual\n",
    "    # and adding them all up and dividing by the relevant dof. Within-group here means \"within a group\n",
    "    # of latency measurements made for one individual\"\n",
    "    wg_sos = 0\n",
    "    wg_dof = 0\n",
    "    for ind in individuals:\n",
    "        \n",
    "        # Build up the within group sum of squares and degrees of freedom:\n",
    "        sos_tmp = ind.sumofsquare_displacements_all()\n",
    "        wg_sos += sos_tmp\n",
    "        dof_tmp = ind.num_replicates_all()-1\n",
    "        wg_dof += dof_tmp\n",
    "            \n",
    "    # Second, displacement due to ALL sources of variation in the experiment. Factor A, Factor B, interaction, error.\n",
    "    # total_variance. This is displacement from the grand mean.\n",
    "    total_sos = 0\n",
    "    total_dof = -1 # dof is number of replicates -1\n",
    "    for ind in individuals:\n",
    "        #ind = individuals[i]\n",
    "        sos_tmp = ind.sumofsquare_displacements_all_from_value(grand_mean)\n",
    "        total_sos += sos_tmp\n",
    "        dof_tmp = ind.num_replicates_all()\n",
    "        total_dof += dof_tmp\n",
    "\n",
    "    # So here's the total variance:\n",
    "    total_variance = total_sos/total_dof\n",
    "    print 'TOTAL variance:',total_variance,'sigma:',np.sqrt(total_variance),'sos:',total_sos,'dof:',total_dof\n",
    "\n",
    "    wg_dof = (total_dof+1) - 3 * 4\n",
    "    wg_variance = wg_sos/wg_dof\n",
    "    print 'ERROR/WG variance:',wg_variance,'sigma:',np.sqrt(wg_variance),'sos:',wg_sos,'dof:',wg_dof\n",
    "\n",
    "    # Now consider the data in relation to each of the two factors in turn (individual and condition).\n",
    "    # These are called the \"simple main effects\".\n",
    "\n",
    "    # Factor A simple main effect: Compute condition_plus_error_sos (Factor A -\n",
    "    # equiv to Temperature in p177 of McKillup).\n",
    "    #CROP\n",
    "    wheat_treatment_mean = 0\n",
    "    corn_treatment_mean = 0\n",
    "    soy_treatment_mean = 0\n",
    "    rice_treatment_mean = 0\n",
    "    for ind in individuals:\n",
    "        #ind = individuals[i]\n",
    "        print 'Add ',ind.wheat_values.mean(),'to wheat_treatment_mean'\n",
    "        wheat_treatment_mean += ind.wheat_values.mean()\n",
    "        corn_treatment_mean += ind.corn_values.mean()\n",
    "        soy_treatment_mean += ind.soy_values.mean()\n",
    "        rice_treatment_mean += ind.rice_values.mean()\n",
    "    \n",
    "    wheat_treatment_mean = wheat_treatment_mean / len(individuals)\n",
    "    corn_treatment_mean = corn_treatment_mean / len(individuals)\n",
    "    soy_treatment_mean = soy_treatment_mean / len(individuals)\n",
    "    rice_treatment_mean = rice_treatment_mean / len(individuals)\n",
    "    \n",
    "    num_replicants = 5 # in this case, num_replicants is 5 each time.\n",
    "    num_rows = len(individuals) # 3 blends\n",
    "    condition_plus_error_sos = num_replicants * num_rows * (np.power(wheat_treatment_mean - grand_mean,2) + np.power(corn_treatment_mean - grand_mean,2) + np.power(soy_treatment_mean - grand_mean,2) + np.power(rice_treatment_mean - grand_mean,2))\n",
    "    condition_plus_error_dof = 3 # 4 conditions - 1 = 3\n",
    "    \n",
    "    condition_plus_error_variance = condition_plus_error_sos / condition_plus_error_dof\n",
    "    print 'CONDITION variance:',condition_plus_error_variance,'sigma:',np.sqrt(condition_plus_error_variance),'sos:',condition_plus_error_sos,'dof:',condition_plus_error_dof\n",
    "    \n",
    "    # Factor B simple main effect. Compute individual_plus_error_sos (p178).\n",
    "    # BLEND\n",
    "    individual_plus_error_sos = 0\n",
    "    for ind in individuals:\n",
    "        #ind = individuals[i]\n",
    "        ind_mean = (ind.wheat_values.mean() + ind.corn_values.mean() + ind.soy_values.mean() + ind.rice_values.mean()) / 4\n",
    "        individual_plus_error_sos += np.power(ind_mean-grand_mean,2)\n",
    "\n",
    "    num_cols = 4 # wheat, corn, soy, rice\n",
    "    individual_plus_error_sos *= num_replicants * num_cols\n",
    "    individual_plus_error_dof = (len(individuals)-1)\n",
    "    \n",
    "    individual_plus_error_variance = individual_plus_error_sos / individual_plus_error_dof\n",
    "    print 'INDIVIDUAL variance:',individual_plus_error_variance,'sigma:',np.sqrt(individual_plus_error_variance),'sos:',individual_plus_error_sos,'dof:',individual_plus_error_dof\n",
    "\n",
    "    # Alternative method to find within group degrees of freedom\n",
    "    wg_dof_alt = (total_dof+1)- ((condition_plus_error_dof+1)*(individual_plus_error_dof+1))\n",
    "    print 'wg_dof:',wg_dof,'wg_dof_alt:',wg_dof_alt\n",
    "    \n",
    "    # One way to find the interaction is by subtraction.\n",
    "    interaction_sos = total_sos - condition_plus_error_sos - individual_plus_error_sos - wg_sos # McKillup p 179\n",
    "    interaction_dof = condition_plus_error_dof * individual_plus_error_dof\n",
    "    interaction_variance = interaction_sos / interaction_dof\n",
    "    print 'INTERACTION variance (by subtraction):',interaction_variance,'sigma:',np.sqrt(interaction_variance),'sos:',interaction_sos,'dof:',interaction_dof\n",
    "\n",
    "    # Alternatively, compute it directly\n",
    "    interaction_sos2 = 0\n",
    "    for ind in individuals:\n",
    "        # For each condition:\n",
    "        #for i in ind.wheat_values:\n",
    "        interaction_sos2 += np.power((ind.wheat_values.mean() - ind.overall_mean() - wheat_mean + grand_mean),2)\n",
    "        #for i in ind.corn_values:\n",
    "        interaction_sos2 += np.power((ind.corn_values.mean() - ind.overall_mean() - corn_mean + grand_mean),2)\n",
    "        #for i in ind.soy_values:\n",
    "        interaction_sos2 += np.power((ind.soy_values.mean() - ind.overall_mean() - soy_mean + grand_mean),2)\n",
    "        #for i in ind.rice_values:\n",
    "        interaction_sos2 += np.power((ind.rice_values.mean() - ind.overall_mean() - rice_mean + grand_mean),2)\n",
    "    interaction_sos2 *= 5\n",
    "    \n",
    "    interaction_variance2 = interaction_sos2 / interaction_dof\n",
    "    print 'INTERACTION variance2 (by computation)):',interaction_variance2,'sigma:',np.sqrt(interaction_variance2),'sos:',interaction_sos2,'dof:',interaction_dof\n",
    "\n",
    "    # Now compute the F ratios\n",
    "    # Have wg_variance, total_variance, condition_plus_error_variance, individual_plus_error_variance and interaction_variance\n",
    "    #\n",
    "    # NB: When reporting must clearly state how F ratios were calculated.\n",
    "    #\n",
    "    \n",
    "    # The website example has both factors fixed, so these are the F ratios:\n",
    "    F_cond = condition_plus_error_variance / wg_variance # fixed\n",
    "    F_ind = individual_plus_error_variance / wg_variance # fixed\n",
    "    F_interaction = interaction_variance / wg_variance\n",
    "\n",
    "    P_cond = 1-special.fdtr(condition_plus_error_dof,wg_dof,F_cond) # dof correct?\n",
    "    P_ind = 1-special.fdtr(individual_plus_error_dof,wg_dof,F_ind)\n",
    "    P_interaction = 1-special.fdtr(interaction_dof,wg_dof,F_interaction)\n",
    "\n",
    "    #F_cond = condition_plus_error_variance / interaction_variance2 # fixed. condition + interaction + error. If both factors were fixed, this would be condition_var/error_var\n",
    "    #F_ind = individual_plus_error_variance / wg_variance # random. (individual var + error var) divided by (error variance) only\n",
    "    #F_interaction = interaction_variance / wg_variance\n",
    "    \n",
    "    # Lastly, what's the probability for this?\n",
    "    #P_cond = 1-special.fdtr(condition_plus_error_dof,wg_dof+interaction_dof,F_cond) # dof correct?\n",
    "    #P_ind = 1-special.fdtr(individual_plus_error_dof,wg_dof,F_ind)\n",
    "    #P_interaction = 1-special.fdtr(interaction_dof,wg_dof,F_interaction)\n",
    "\n",
    "    print '\\nF_cond:{0} P_cond:{1} '.format(F_cond,P_cond)\n",
    "    print 'F_ind:{0} P_ind:{1}'.format(F_ind,P_ind)\n",
    "    print 'F_interaction:{0} P_interaction:{1}'.format(F_interaction,P_interaction)\n",
    "    \n",
    "    print '\\n'\n",
    "    print 'Source of var, Sumof Squares, df, Mean square , F ratio        ','P'\n",
    "    print '-------------------------------------------------------------------'\n",
    "    print '{0}, {1}, {2}, {3}, {4}, {5}'.format('Individual   ',individual_plus_error_sos,individual_plus_error_dof,individual_plus_error_variance,F_ind,P_ind)\n",
    "    print '{0}, {1}, {2}, {3}, {4}, {5}'.format('Condition    ',condition_plus_error_sos,condition_plus_error_dof,condition_plus_error_variance,F_cond,P_cond)\n",
    "    print '{0}, {1}, {2}, {3}, {4}, {5}'.format('Indiv x Cond ',interaction_sos,interaction_dof,interaction_variance2,F_interaction,P_interaction)\n",
    "    print '{0}, {1}, {2}, {3}, {4}, {5}'.format('Error        ',wg_sos,wg_dof,wg_variance,'-','-')\n",
    "\n",
    "\n",
    "blendX = individual('X')\n",
    "blendX.wheat_values = np.array([123,156,112,100,168])\n",
    "blendX.corn_values = np.array([128,150,174,116,109])\n",
    "blendX.soy_values = np.array([166,178,187,153,195])\n",
    "blendX.rice_values = np.array([151,125,117,155,158])\n",
    "\n",
    "blendY = individual('Y')\n",
    "blendY.wheat_values = np.array([135,130,176,120,155]) # sos: 104526\n",
    "blendY.corn_values = np.array([175,132,120,187,184])\n",
    "blendY.soy_values = np.array([140,145,159,131,126])\n",
    "blendY.rice_values = np.array([167,183,142,167,168])\n",
    "\n",
    "blendZ = individual('Z')\n",
    "blendZ.wheat_values = np.array([156,180,147,146,193])\n",
    "blendZ.corn_values = np.array([186,138,178,176,190])\n",
    "blendZ.soy_values = np.array([185,206,188,165,188])\n",
    "blendZ.rice_values = np.array([175,173,154,191,169])\n",
    "\n",
    "individuals = [blendX,blendY,blendZ]\n",
    "\n",
    "# Now actually call the two factor ANOVA\n",
    "twofactor_anova(individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
